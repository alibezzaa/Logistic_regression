setwd("~/Desktop/analyse de données/My Course/Logistic regression")
# example is from the book "Marketing Research : An applied orientation"
Loyalty = read.csv2("Table 18.6.csv")
names(Loyalty) = c("no", "fidelite", "marque", "produit", "achat")
names(Loyalty) = c("no", "fidelite", "marque", "produit", "achat")
summary(Loyalty)
table(Loyalty$fidelite, Loyalty$marque)
plot(Loyalty$marque, Loyalty$fidelite)
modele1 = glm(fidelite ~ marque, data = Loyalty,
family = binomial())
summary(modele1)
Loyalty$fidelite
Loyalty$marque
setwd("~/Desktop/analyse de données/My Course/Logistic regression")
donnees = read.csv2("Table 18.6.csv")
head(donnees)
names(donnees) = c("fidelite", "marque", "produit", "shopping")
head(donnees)
names(donnees) = c("no","fidelite", "marque", "produit", "shopping")
head(donnees)
donnees = read.csv2("Table 18.6.csv")
names(donnees) = c("no","fidelite", "marque", "produit", "shopping")
head(donnees)
model1 = glm(formula = fidelite~1, data = donnees,
family = binomial())
summary(model1)
table(donnees$fidelite)
p = 15/30
q = 15/30
Odds = p/q
log(Odds)
model2 = glm(formula = fidelite~ marque, data = donnees,
family = binomial())
summary(model2)
donnees$fidelite
donnees$marque
myData = read.csv2("Table 18.6.csv")
head(myData)
names("no", "fidelite", "marque", "produit", "achat")
names(myData) = c("no", "fidelite", "marque", "produit", "achat")
head(myData)
summary(myData)
model1 = glm(fidelite~1, family = binomial(), data = myData)
summary(model1)
table(myData$fidelite)
p = 15/30
q = 15/30
odds_Ratio= p/q
log(odds_Ratio)
options(scipen = 0)
model1$coefficients[1]
options(scipen = 0)
model1$coefficients[1]
options(scipen = 999)
model1$coefficients[1]
model2 = glm(fidelite~ marque, family = binomial(), data = myData)
summary(model2)
myData$fidelite
myData$marque
plot(myData$marque, myData$fidelite)
install.packages("mlbench")
library(mlbench)
mydata = "PimaIndiansDiabetes2"
mydata = read.csv("PimaIndiansDiabetes2.csv")
data("PimaIndiansDiabetes2", package = "mlbench")
View(PimaIndiansDiabetes2)
head(PimaIndiansDiabetes2)
model = glm(diabetes ~ ., data = PimaIndiansDiabetes2)
model = glm(diabetes ~ ., data = PimaIndiansDiabetes2,
family = binomial())
prob = predict(model, type = "response")
predict.classes = ifelse(prob> 0.5, "pos", "neg")
head(predict.classes)
library(tidyverse)
mydata = PimaIndiansDiabetes2 %>% dplyr::select_if(is.numeric)
View(PimaIndiansDiabetes2)
predictors = colnames(mydata)
mydata = mydata %>% mutate(logit = log(prob/(1- prob))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
setwd("~/Desktop/analyse de données/My Course/Logistic regression/Excel_Chapter_Tables_Input_Data")
library(car)
myData = read.csv("Table 18.6.csv", sep = ";")
myData = myData[,-1]
summary(myData)
names(myData) = c("Fidelite", "Marque", "Produit", "Experience_achat")
library(ggplot2)
nuage = ggplot(myData, aes(Marque, Fidelite))+ geom_point()
nuage
model1 = glm(Fidelite ~ Marque,
family = binomial(), data = myData)
prob = predict(model1, type = "response")
predict.classes = ifelse(prob> 0.5, "Fid", "NoFid")
head(predict.classes)
mydata2 = myData %>% dplyr::select_if(is.numeric)
View(myData)
predictors = colnames(myData)
mydata2 = mydata2 %>% mutate(logit = log(prob/(1- prob)))
View(mydata2)
mydata2 = mydata2 %>% mutate(logit = log(prob/(1- prob))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
View(mydata2)
?gather
View(mydata2)
View(myData)
ggplot(mydata2, aes(logit, preditor.value)) +
geom_point(size = 0.5, alpha = 0.5)+
geom_smooth(method = "loess")+
facet_wrap(~predictors, scales = "free_y")
ggplot(mydata2, aes(logit, predictor.value)) +
geom_point(size = 0.5, alpha = 0.5)+
geom_smooth(method = "loess")+
facet_wrap(~predictors, scales = "free_y")
# tester la linéarité
library(tidyverse)
View(mydata2)
View(myData)
myData = read.csv("Table 18.6.csv", sep = ";")
myData = myData[,-1]
names(myData) = c("Fidelite", "Marque", "Produit", "Experience_achat")
model1 = glm(Fidelite ~ Marque,
family = binomial(), data = myData)
# tester la linéarité
library(tidyverse)
prob = predict(model1, type = "response")
predict.classes = ifelse(prob> 0.5, "Fid", "NoFid")
head(predict.classes)
mydata2 = myData %>% dplyr::select_if(is.numeric)
predictors = colnames(myData)
mydata2 = myData %>% mutate(logit = log(prob/(1- prob))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
View(mydata2)
View(myData)
mydata2 = myData %>% mutate(logit = log(prob/(1- prob))) %>%
gather(key = "predictors", value = "predictor.value")
View(mydata2)
mydata2 = myData %>% mutate(logit = log(prob/(1- prob))) %>%
gather(key = "predictors", value = "predictor.value", logit)
View(mydata2)
mydata2 = myData %>% mutate(logit = log(prob/(1- prob)))
View(myData)
predictors = colnames(myData[2:4])
mydata2 = myData %>% mutate(logit = log(prob/(1- prob))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
mydata2 = myData %>% mutate(logit = log(prob/(1- prob)))
mydata2 = myData %>% mutate(logit = log(prob/(1- prob))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
ggplot(mydata2, aes(logit, predictor.value)+
ggplot(mydata2, aes(logit, predictor.value)+
ggplot(mydata2, aes(logit, predictor.value)) +
geom_point(size = 0.5)+ geom_smooth(method = "loess")+
facet_wrap(~ predictors, scales = "free_y" )
ggplot(mydata2, aes(logit, predictor.value)) +
geom_point(size = 0.5, alpha = 0.5)+ geom_smooth(method = "loess")+
facet_wrap(~ predictors, scales = "free_y")
ggplot(mydata2, aes(logit, predictor.value)) +
geom_point(size = 0.5, alpha = 0.5)+ geom_smooth(method = "loess")+
facet_wrap(~ predictors, scales = "free_y")
model1 = glm(Fidelite ~ .,
family = binomial(), data = myData)
summary(model1)
prob = predict(model1, type = "response")
mydata2 = myData %>% dplyr::select_if(is.numeric)
predictors = colnames(myData[2:4])
mydata2 = myData %>% mutate(logit = log(prob/(1- prob))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
ggplot(mydata2, aes(logit, predictor.value)) +
geom_point(size = 0.5, alpha = 0.5)+ geom_smooth(method = "loess")+
facet_wrap(~ predictors, scales = "free_y")
setwd("~/Desktop/analyse de données/My Course/Logistic regression/Excel_Chapter_Tables_Input_Data")
library(car)
myData = read.csv("Table 18.6.csv", sep = ";")
myData = myData[,-1]
summary(myData)
names(myData) = c("Fidelite", "Marque", "Produit", "Experience_achat")
library(ggplot2)
nuage = ggplot(myData, aes(Marque, Fidelite))+ geom_point()
nuage
model0 = glm(Fidelite~1, data = myData, family = binomial())
summary(model0)
# inspecter les données
head(myData)
summary(model1)
model1 = glm(Fidelite ~ .,
family = binomial(), data = myData)
summary(model1)
# tester l'hypothèse de linéarité
library(tidyverse)
prob = predict(model1, type = "response")
predictors = colnames(myData[2:4])
View(myData)
mydata2 = myData %>% mutate(logit = log(prob/(1- prob))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
ggplot(mydata2, aes(logit, predictor.value)) +
geom_point(size = 0.5, alpha = 0.5)+ geom_smooth(method = "loess")+
facet_wrap(~ predictors, scales = "free_y")
mydata2 = myData[2:4] %>% mutate(logit = log(prob/(1- prob))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
ggplot(mydata2, aes(logit, predictor.value)) +
geom_point(size = 0.5, alpha = 0.5)+ geom_smooth(method = "loess")+
facet_wrap(~ predictors, scales = "free_y")
vif(model1)
myData$residus = rstandard(model1)
myData$large_resid = myData$residus > 2 | myData$residus < -2 # résidus larges
myData$leverage = hatvalues(model1) # seuil = 3*(k+1)/n = 0.399
hist(myData$residus) # normalité
